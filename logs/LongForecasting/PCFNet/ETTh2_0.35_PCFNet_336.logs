Args in experiment:
Namespace(enable_visual=False, fusion_layers=2, d_model=256, n_heads=8, attn_dropout=0.15, d_ff=None, top_k=3, num_kernels=5, encoder_layers=2, hidden_dim=None, coef_scale=0.1, tfactor=0.5, revin=1, ma_type='ema', ema_a=0.3, ema_b=0.3, alpha=0.35, dropout=0.1, batch_size=64, is_training=1, model_id='ETTh2_96_336', model='PCFNet', data='ETTh2', root_path='D:\\work\\datasets\\all_datasets/ETT-small/', data_path='ETTh2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=336, seasonal_patterns='Monthly', enc_in=7, embed='timeF', activation='gelu', num_workers=0, itr=1, train_epochs=10, embedding_epochs=5, patience=3, pct_start=0.2, learning_rate=0.0002, embedding_lr=0.0005, des='Exp', loss='MSE', lradj='type1', use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', use_dtw=False, inverse=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_96_336_PCFNet_ETTh2_bs64_ftM_sl96_ll48_pre336_dm256_nh8_dffNone_tk3_nk5_el2_fl2_hdNone_cs0.1_tf0.5_dp01_adr015_em0.3_lr00002_ep10_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 2.0552967
	speed: 0.0414s/iter; left time: 48.8549s
Epoch: 1 cost time: 5.142125129699707
Epoch: 1, Steps: 128 | Train Loss: 2.1314651 Vali Loss: 1.8688718 Test Loss: 0.4147069
Validation loss decreased (inf --> 1.868872).  Saving model ...
	iters: 100, epoch: 2 | loss: 2.0776770
	speed: 0.0555s/iter; left time: 58.3889s
Epoch: 2 cost time: 4.627365350723267
Epoch: 2, Steps: 128 | Train Loss: 2.0558782 Vali Loss: 1.8482491 Test Loss: 0.4014103
Validation loss decreased (1.868872 --> 1.848249).  Saving model ...
	iters: 100, epoch: 3 | loss: 2.1624646
	speed: 0.0592s/iter; left time: 54.7335s
Epoch: 3 cost time: 4.731494426727295
Epoch: 3, Steps: 128 | Train Loss: 2.0257899 Vali Loss: 1.8407245 Test Loss: 0.3980592
Validation loss decreased (1.848249 --> 1.840725).  Saving model ...
	iters: 100, epoch: 4 | loss: 2.1729741
	speed: 0.0570s/iter; left time: 45.3924s
Epoch: 4 cost time: 4.802401542663574
Epoch: 4, Steps: 128 | Train Loss: 2.0158355 Vali Loss: 1.8380877 Test Loss: 0.3959273
Validation loss decreased (1.840725 --> 1.838088).  Saving model ...
	iters: 100, epoch: 5 | loss: 1.8447704
	speed: 0.0591s/iter; left time: 39.5653s
Epoch: 5 cost time: 4.8293616771698
Epoch: 5, Steps: 128 | Train Loss: 2.0098208 Vali Loss: 1.8386582 Test Loss: 0.3944327
EarlyStopping counter: 1 out of 3
	iters: 100, epoch: 6 | loss: 2.1301880
	speed: 0.0583s/iter; left time: 31.5444s
Epoch: 6 cost time: 4.611549615859985
Epoch: 6, Steps: 128 | Train Loss: 2.0060610 Vali Loss: 1.8384966 Test Loss: 0.3931167
EarlyStopping counter: 2 out of 3
	iters: 100, epoch: 7 | loss: 1.8721595
	speed: 0.0556s/iter; left time: 22.9735s
Epoch: 7 cost time: 4.515556335449219
Epoch: 7, Steps: 128 | Train Loss: 2.0036362 Vali Loss: 1.8368632 Test Loss: 0.3921413
Validation loss decreased (1.838088 --> 1.836863).  Saving model ...
	iters: 100, epoch: 8 | loss: 2.1490698
	speed: 0.0531s/iter; left time: 15.1475s
Epoch: 8 cost time: 4.400663375854492
Epoch: 8, Steps: 128 | Train Loss: 2.0026558 Vali Loss: 1.8372944 Test Loss: 0.3923909
EarlyStopping counter: 1 out of 3
	iters: 100, epoch: 9 | loss: 2.0168843
	speed: 0.0539s/iter; left time: 8.4696s
Epoch: 9 cost time: 4.276045322418213
Epoch: 9, Steps: 128 | Train Loss: 2.0020554 Vali Loss: 1.8382965 Test Loss: 0.3921780
EarlyStopping counter: 2 out of 3
	iters: 100, epoch: 10 | loss: 1.9773293
	speed: 0.0525s/iter; left time: 1.5237s
Epoch: 10 cost time: 4.296860933303833
Epoch: 10, Steps: 128 | Train Loss: 2.0024031 Vali Loss: 1.8388590 Test Loss: 0.3920886
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh2_96_336_PCFNet_ETTh2_bs64_ftM_sl96_ll48_pre336_dm256_nh8_dffNone_tk3_nk5_el2_fl2_hdNone_cs0.1_tf0.5_dp01_adr015_em0.3_lr00002_ep10_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (2545, 336, 7) (2545, 336, 7)
test shape: (2545, 336, 7) (2545, 336, 7)
mse:0.3921412527561188, mae:0.4110465347766876, dtw:Not calculated
