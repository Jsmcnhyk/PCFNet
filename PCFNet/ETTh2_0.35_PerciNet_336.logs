Args in experiment:
Namespace(enable_visual=True, fusion_layers=2, d_model=256, n_heads=8, attn_dropout=0.15, d_ff=None, top_k=3, num_kernels=5, encoder_layers=2, hidden_dim=None, coef_scale=0.1, tfactor=0.5, revin=1, ma_type='ema', ema_a=0.3, ema_b=0.3, alpha=0.35, dropout=0.1, batch_size=64, is_training=1, model_id='ETTh2_96_336', model='PerciNet', data='ETTh2', root_path='D:\\work\\datasets\\all_datasets/ETT-small/', data_path='ETTh2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=336, seasonal_patterns='Monthly', enc_in=7, embed='timeF', activation='gelu', num_workers=0, itr=1, train_epochs=10, embedding_epochs=5, patience=3, pct_start=0.2, learning_rate=0.0002, embedding_lr=0.0005, des='Exp', loss='MSE', lradj='type1', use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', use_dtw=False, inverse=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_96_336_PerciNet_ETTh2_bs64_ftM_sl96_ll48_pre336_dm256_nh8_dffNone_tk3_nk5_el2_fl2_hdNone_cs0.1_tf0.5_dp01_adr015_em0.3_lr00002_ep10_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 2.0552967
	speed: 0.2188s/iter; left time: 258.3787s
Epoch: 1 cost time: 27.36046862602234
Epoch: 1, Steps: 128 | Train Loss: 2.1314651 Vali Loss: 1.8688718 Test Loss: 0.4147069
Validation loss decreased (inf --> 1.868872).  Saving model ...
	iters: 100, epoch: 2 | loss: 2.0776770
	speed: 0.2871s/iter; left time: 302.3014s
Epoch: 2 cost time: 24.399244785308838
Epoch: 2, Steps: 128 | Train Loss: 2.0558782 Vali Loss: 1.8482491 Test Loss: 0.4014103
Validation loss decreased (1.868872 --> 1.848249).  Saving model ...
	iters: 100, epoch: 3 | loss: 2.1624646
	speed: 0.3158s/iter; left time: 292.0887s
Epoch: 3 cost time: 25.877212285995483
Epoch: 3, Steps: 128 | Train Loss: 2.0257899 Vali Loss: 1.8407245 Test Loss: 0.3980592
Validation loss decreased (1.848249 --> 1.840725).  Saving model ...
	iters: 100, epoch: 4 | loss: 2.1729741
	speed: 0.3068s/iter; left time: 244.5569s
Epoch: 4 cost time: 26.304067611694336
Epoch: 4, Steps: 128 | Train Loss: 2.0158355 Vali Loss: 1.8380877 Test Loss: 0.3959273
Validation loss decreased (1.840725 --> 1.838088).  Saving model ...
	iters: 100, epoch: 5 | loss: 1.8447704
	speed: 0.3218s/iter; left time: 215.2775s
Epoch: 5 cost time: 26.473981380462646
Epoch: 5, Steps: 128 | Train Loss: 2.0098208 Vali Loss: 1.8386582 Test Loss: 0.3944327
EarlyStopping counter: 1 out of 3
	iters: 100, epoch: 6 | loss: 2.1301880
	speed: 0.3057s/iter; left time: 165.3595s
Epoch: 6 cost time: 24.508575201034546
Epoch: 6, Steps: 128 | Train Loss: 2.0060610 Vali Loss: 1.8384966 Test Loss: 0.3931167
EarlyStopping counter: 2 out of 3
	iters: 100, epoch: 7 | loss: 1.8721595
	speed: 0.3007s/iter; left time: 124.1827s
Epoch: 7 cost time: 25.357653379440308
Epoch: 7, Steps: 128 | Train Loss: 2.0036362 Vali Loss: 1.8368632 Test Loss: 0.3921413
Validation loss decreased (1.838088 --> 1.836863).  Saving model ...
	iters: 100, epoch: 8 | loss: 2.1490698
	speed: 0.3033s/iter; left time: 86.4502s
Epoch: 8 cost time: 26.002554655075073
Epoch: 8, Steps: 128 | Train Loss: 2.0026558 Vali Loss: 1.8372944 Test Loss: 0.3923909
EarlyStopping counter: 1 out of 3
	iters: 100, epoch: 9 | loss: 2.0168843
	speed: 0.2984s/iter; left time: 46.8562s
Epoch: 9 cost time: 23.80576753616333
Epoch: 9, Steps: 128 | Train Loss: 2.0020554 Vali Loss: 1.8382965 Test Loss: 0.3921780
EarlyStopping counter: 2 out of 3
	iters: 100, epoch: 10 | loss: 1.9773293
	speed: 0.2934s/iter; left time: 8.5097s
Epoch: 10 cost time: 24.708272695541382
Epoch: 10, Steps: 128 | Train Loss: 2.0024031 Vali Loss: 1.8388590 Test Loss: 0.3920886
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh2_96_336_PerciNet_ETTh2_bs64_ftM_sl96_ll48_pre336_dm256_nh8_dffNone_tk3_nk5_el2_fl2_hdNone_cs0.1_tf0.5_dp01_adr015_em0.3_lr00002_ep10_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (2545, 336, 7) (2545, 336, 7)
test shape: (2545, 336, 7) (2545, 336, 7)
mse:0.3921412527561188, mae:0.4110465347766876, dtw:Not calculated
