Args in experiment:
Namespace(enable_visual=True, fusion_layers=1, d_model=64, n_heads=8, attn_dropout=0.15, d_ff=None, top_k=3, num_kernels=3, encoder_layers=2, hidden_dim=None, coef_scale=0.1, tfactor=0.5, revin=1, ma_type='ema', ema_a=0.3, ema_b=0.3, alpha=0.35, dropout=0.1, batch_size=64, is_training=1, model_id='ETTh1_96_96', model='PerciNet', data='ETTh1', root_path='D:\\work\\datasets\\all_datasets/ETT-small/', data_path='ETTh1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, seasonal_patterns='Monthly', enc_in=7, embed='timeF', activation='gelu', num_workers=0, itr=1, train_epochs=10, embedding_epochs=5, patience=3, pct_start=0.2, learning_rate=0.0004, embedding_lr=0.0005, des='Exp', loss='MSE', lradj='type1', use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', use_dtw=False, inverse=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_96_96_PerciNet_ETTh1_bs64_ftM_sl96_ll48_pre96_dm64_nh8_dffNone_tk3_nk3_el2_fl1_hdNone_cs0.1_tf0.5_dp01_adr015_em0.3_lr00004_ep10_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8449
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 1.5106375
	speed: 0.1000s/iter; left time: 122.0923s
Epoch: 1 cost time: 13.203218698501587
Epoch: 1, Steps: 132 | Train Loss: 1.5298779 Vali Loss: 1.7922324 Test Loss: 0.3821874
Validation loss decreased (inf --> 1.792232).  Saving model ...
	iters: 100, epoch: 2 | loss: 1.4539835
	speed: 0.1678s/iter; left time: 182.7714s
Epoch: 2 cost time: 13.735923290252686
Epoch: 2, Steps: 132 | Train Loss: 1.4332708 Vali Loss: 1.7744576 Test Loss: 0.3770308
Validation loss decreased (1.792232 --> 1.774458).  Saving model ...
	iters: 100, epoch: 3 | loss: 1.4486322
	speed: 0.1680s/iter; left time: 160.7548s
Epoch: 3 cost time: 14.447095394134521
Epoch: 3, Steps: 132 | Train Loss: 1.4135297 Vali Loss: 1.7628352 Test Loss: 0.3732556
Validation loss decreased (1.774458 --> 1.762835).  Saving model ...
	iters: 100, epoch: 4 | loss: 1.4575305
	speed: 0.1722s/iter; left time: 142.0485s
Epoch: 4 cost time: 14.171168327331543
Epoch: 4, Steps: 132 | Train Loss: 1.4044651 Vali Loss: 1.7578103 Test Loss: 0.3715473
Validation loss decreased (1.762835 --> 1.757810).  Saving model ...
	iters: 100, epoch: 5 | loss: 1.4028172
	speed: 0.1667s/iter; left time: 115.5036s
Epoch: 5 cost time: 13.832549095153809
Epoch: 5, Steps: 132 | Train Loss: 1.4000910 Vali Loss: 1.7556201 Test Loss: 0.3707179
Validation loss decreased (1.757810 --> 1.755620).  Saving model ...
	iters: 100, epoch: 6 | loss: 1.3706928
	speed: 0.1725s/iter; left time: 96.7913s
Epoch: 6 cost time: 13.835655450820923
Epoch: 6, Steps: 132 | Train Loss: 1.3976194 Vali Loss: 1.7535045 Test Loss: 0.3712122
Validation loss decreased (1.755620 --> 1.753504).  Saving model ...
	iters: 100, epoch: 7 | loss: 1.3613013
	speed: 0.1644s/iter; left time: 70.5189s
Epoch: 7 cost time: 13.717641115188599
Epoch: 7, Steps: 132 | Train Loss: 1.3968348 Vali Loss: 1.7545663 Test Loss: 0.3706607
EarlyStopping counter: 1 out of 3
	iters: 100, epoch: 8 | loss: 1.3791287
	speed: 0.1691s/iter; left time: 50.2350s
Epoch: 8 cost time: 13.691246747970581
Epoch: 8, Steps: 132 | Train Loss: 1.3960783 Vali Loss: 1.7528836 Test Loss: 0.3706761
Validation loss decreased (1.753504 --> 1.752884).  Saving model ...
	iters: 100, epoch: 9 | loss: 1.3805166
	speed: 0.1632s/iter; left time: 26.9208s
Epoch: 9 cost time: 13.250319480895996
Epoch: 9, Steps: 132 | Train Loss: 1.3960555 Vali Loss: 1.7539812 Test Loss: 0.3706129
EarlyStopping counter: 1 out of 3
	iters: 100, epoch: 10 | loss: 1.4445174
	speed: 0.1683s/iter; left time: 5.5555s
Epoch: 10 cost time: 13.682368516921997
Epoch: 10, Steps: 132 | Train Loss: 1.3957704 Vali Loss: 1.7536396 Test Loss: 0.3706151
EarlyStopping counter: 2 out of 3
>>>>>>>testing : ETTh1_96_96_PerciNet_ETTh1_bs64_ftM_sl96_ll48_pre96_dm64_nh8_dffNone_tk3_nk3_el2_fl1_hdNone_cs0.1_tf0.5_dp01_adr015_em0.3_lr00004_ep10_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (2785, 96, 7) (2785, 96, 7)
test shape: (2785, 96, 7) (2785, 96, 7)
mse:0.37067610025405884, mae:0.389990895986557, dtw:Not calculated
